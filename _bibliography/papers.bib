---
---

@article{https://doi.org/10.48550/arxiv.2203.08654,
  doi = {10.48550/ARXIV.2203.08654},
  url = {https://arxiv.org/abs/2203.08654},
  pdf = {https://arxiv.org/pdf/2203.08654.pdf},
  author = {Imani, Ayyoob and Şenel, Lütfi Kerem and Jalili Sabet, Masoud and Yvon, François and Schütze, Hinrich},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Graph Neural Networks for Multiparallel Word Alignment},
  journal = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license},
  abbr={ACL},
  selected={true},
  bibtex_show={true},
}

@article{https://doi.org/10.48550/arxiv.2203.10010,
  doi = {10.48550/ARXIV.2203.10010},
  url = {https://arxiv.org/abs/2203.10010},
  pdf = {https://arxiv.org/pdf/2203.10010.pdf},
  author = {Weissweiler, Leonie and Hofmann, Valentin and Jalili Sabet, Masoud and Schütze, Hinrich},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {CaMEL: Case Marker Extraction without Labels},
  journal = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International},
  abbr={ACL},
  bibtex_show={true},
}

@inproceedings{imanigooghari-etal-2021-graph,
    abbr={EMNLP},
    title = "Graph Algorithms for Multiparallel Word Alignment",
    author = {Imani*, Ayyoob  and
      Jalili Sabet*, Masoud  and
      Senel, Lutfi Kerem  and
      Dufter, Philipp  and
      Yvon, Fran{\c{c}}ois  and
      Sch{\"u}tze, Hinrich},
    booktitle = "EMNLP",
    year = "2021",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.665",
    pdf = "https://aclanthology.org/2021.emnlp-main.665.pdf",
    bib = "https://aclanthology.org/2021.emnlp-main.665.bib",
    doi = "10.18653/v1/2021.emnlp-main.665",
    pages = "8457--8469",
    abstract = "With the advent of end-to-end deep learning approaches in machine translation, interest in word alignments initially decreased; however, they have again become a focus of research more recently. Alignments are useful for typological research, transferring formatting like markup to translated texts, and can be used in the decoding of machine translation systems. At the same time, massively multilingual processing is becoming an important NLP scenario, and pretrained language and machine translation models that are truly multilingual are proposed. However, most alignment algorithms rely on bitexts only and do not leverage the fact that many parallel corpora are multiparallel. In this work, we exploit the multiparallelity of corpora by representing an initial set of bilingual alignments as a graph and then predicting additional edges in the graph. We present two graph algorithms for edge prediction: one inspired by recommender systems and one based on network link prediction. Our experimental results show absolute improvements in F1 of up to 28{\%} over the baseline bilingual word aligner in different datasets.",
    selected={true},
    bibtex_show={true},
}

@inproceedings{imanigooghari-etal-2021-parcoure,
    abbr={ACL},
    title = "{P}ar{C}our{E}: A Parallel Corpus Explorer for a Massively Multilingual Corpus",
    author = {Imani, Ayyoob  and
      Jalili Sabet, Masoud  and
      Dufter, Philipp  and
      Cysou, Michael  and
      Sch{\"u}tze, Hinrich},
    booktitle = "ACL Demo",
    year = "2021",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-demo.8",
    pdf = "https://aclanthology.org/2021.acl-demo.8.pdf",
    bib = "https://aclanthology.org/2021.acl-demo.8.bib",
    doi = "10.18653/v1/2021.acl-demo.8",
    pages = "63--72",
    abstract = "With more than 7000 languages worldwide, multilingual natural language processing (NLP) is essential both from an academic and commercial perspective. Researching typological properties of languages is fundamental for progress in multilingual NLP. Examples include assessing language similarity for effective transfer learning, injecting inductive biases into machine learning models or creating resources such as dictionaries and inflection tables. We provide ParCourE, an online tool that allows to browse a word-aligned parallel corpus, covering 1334 languages. We give evidence that this is useful for typological research. ParCourE can be set up for any parallel corpus and can thus be used for typological research on other corpora as well as for exploring their quality and properties.",
    bibtex_show={true},
}

@inproceedings{jalili-sabet-etal-2020-simalign,
    abbr={EMNLP},
    title = "{S}im{A}lign: High Quality Word Alignments Without Parallel Training Data Using Static and Contextualized Embeddings",
    author = {Jalili Sabet*, Masoud  and
      Dufter*, Philipp  and
      Yvon, Fran{\c{c}}ois  and
      Sch{\"u}tze, Hinrich},
    booktitle = "EMNLP Findings",
    year = "2020",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.147",
    pdf = "https://aclanthology.org/2020.findings-emnlp.147.pdf",
    bib = "https://aclanthology.org/2020.findings-emnlp.147.bib",
    doi = "10.18653/v1/2020.findings-emnlp.147",
    pages = "1627--1643",
    abstract = "Word alignments are useful for tasks like statistical and neural machine translation (NMT) and cross-lingual annotation projection. Statistical word aligners perform well, as do methods that extract alignments jointly with translations in NMT. However, most approaches require parallel training data and quality decreases as less training data is available. We propose word alignment methods that require no parallel data. The key idea is to leverage multilingual word embeddings {--} both static and contextualized {--} for word alignment. Our multilingual embeddings are created from monolingual data only without relying on any parallel data or dictionaries. We find that alignments created from embeddings are superior for four and comparable for two language pairs compared to those produced by traditional statistical aligners {--} even with abundant parallel data; e.g., contextualized embeddings achieve a word alignment F1 for English-German that is 5 percentage points higher than eflomal, a high-quality statistical aligner, trained on 100k parallel sentences.",
    selected={true},
    bibtex_show={true},
}

@article{asgari-etal-2020-sampling,
  abbr={arXiv},
  doi = {10.48550/ARXIV.2012.11657},
  url = {https://arxiv.org/abs/2012.11657},
  pdf = {https://arxiv.org/pdf/2012.11657.pdf},
  author = {Asgari*, Ehsaneddin and Jalili Sabet*, Masoud and Dufter, Philipp and Ringlstetter, Christopher and Schütze, Hinrich},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Subword Sampling for Low Resource Word Alignment},
  journal = {arXiv},
  year = {2020},
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International},
  bibtex_show={true},
}

@InProceedings{Ghadery-etal-2019-LICD,
  abbr={ECIR},
  author="Ghadery, Erfan
  and Movahedi, Sajad
  and Jalili Sabet, Masoud
  and Faili, Heshaam
  and Shakery, Azadeh",
  title="LICD: A Language-Independent Approach for Aspect Category Detection",
  booktitle="ECIR",
  year="2019",
  publisher="Springer International Publishing",
  address="Cham",
  pages="575--589",
  abstract="Aspect-based sentiment analysis (ABSA) deals with processing and summarizing customer reviews and has been a topic of interest in recent years. Given a set of predefined categories, Aspect Category Detection (ACD), as a subtask of ABSA, aims to assign a subset of these categories to a given review sentence. Thanks to the existence of websites such as Yelp and TripAdvisor, there exist a huge amount of reviews in several languages, and therefore the need for language-independent methods in this task seems necessary. In this paper, we propose Language-Independent Category Detector (LICD), a supervised method based on text matching without the need for any language-specific tools and hand-crafted features for identifying aspect categories. For a given sentence, our proposed method performs ACD based on two hypotheses: First, a category should be assigned to a sentence if there is a high semantic similarity between the sentence and a set of representative words of that category. Second, a category should be assigned to a sentence if sentences with high semantic and structural similarity to that sentence belong to that category. To apply the former hypothesis, we used soft cosine measure, and for the latter, word mover's distance measure is utilized. Using these two measures, for a given sentence we calculate a set of similarity scores as features for a one-vs-all logistic regression classifier per category. Experimental results on the multilingual SemEval-2016 datasets in the restaurant domain demonstrate that our approach outperforms baseline methods in English, Russian, and Dutch languages, and obtains competitive results with the strong deep neural network-based baselines in French, Turkish, and Spanish languages.",
  bibtex_show={true},
}


@article{Negri2017,
  abbr={MT Journal},
	affiliation = {Fondazione Bruno Kessler; Fondazione Bruno Kessler, Università degli Studi di Trento; School of Electrical and Computer Engineering, University of Tehran},
	author = {Negri, Matteo and Ataman, Duygu and Sabet, Masoud Jalili and Turchi, Marco and Federico, Marcello},
	copyright = {Springer Science+Business Media Dordrecht},
	doi = {10.1007/s10590-017-9191-5},
	journal = {Machine Translation},
	keywords = {Translation memories; Machine learning; Data cleaning},
	language = {English},
	pages = {93-115},
	title = {Automatic translation memory cleaning},
	year = {2017},
	abstract = {We address the problem of automatically cleaning a translation memory (TM) by identifying problematic translation units (TUs). In this context, we treat as “problematic TUs” those containing useless translations from the point of view of the user of a computer-assisted translation tool. We approach TM cleaning both as a supervised and as an unsupervised learning problem. In both cases, we take advantage of Translation Memory open-source purifier, an open-source TM cleaning tool also presented in this paper. The two learning paradigms are evaluated on different benchmarks extracted from MyMemory, the world’s largest public TM. Our results indicate the effectiveness of the supervised approach in the ideal condition in which labelled training data is available, and the viability of the unsupervised solution for challenging situations in which training data is not accessible.},
  bibtex_show={true},
}

@inproceedings{jalili-sabet-etal-2016-tmop,
    abbr={ACL},
    title = "{TM}op: a Tool for Unsupervised Translation Memory Cleaning",
    author = "Jalili Sabet, Masoud  and
      Negri, Matteo  and
      Turchi, Marco  and
      C. de Souza, Jos{\'e} G.  and
      Federico, Marcello",
    booktitle = "ACL Demo",
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P16-4009",
    pdf = "https://aclanthology.org/P16-4009.pdf",
    bib = "https://aclanthology.org/P16-4009.bib",
    doi = "10.18653/v1/P16-4009",
    pages = "49--54",
    bibtex_show={true},
}

@inproceedings{jalili-sabet-etal-2016-unsupervised,
    abbr={ACL},
    title = "An Unsupervised Method for Automatic Translation Memory Cleaning",
    author = "Jalili Sabet, Masoud  and
      Negri, Matteo  and
      Turchi, Marco  and
      Barbu, Eduard",
    booktitle = "ACL",
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P16-2047",
    pdf = "https://aclanthology.org/P16-2047.pdf",
    bib = "https://aclanthology.org/P16-2047.bib",
    doi = "10.18653/v1/P16-2047",
    pages = "287--292",
    bibtex_show={true},
}

@inproceedings{jalili-sabet-etal-2016-improving,
    abbr={Coling},
    title = "Improving Word Alignment of Rare Words with Word Embeddings",
    author = "Jalili Sabet, Masoud  and
      Faili, Heshaam  and
      Haffari, Gholamreza",
    booktitle = "Coling",
    year = "2016",
    address = "Osaka, Japan",
    publisher = "The COLING 2016 Organizing Committee",
    url = "https://aclanthology.org/C16-1302",
    pdf = "https://aclanthology.org/C16-1302.pdf",
    bib = "https://aclanthology.org/C16-1302.bib",
    pages = "3209--3215",
    abstract = "We address the problem of inducing word alignment for language pairs by developing an unsupervised model with the capability of getting applied to other generative alignment models. We approach the task by: i)proposing a new alignment model based on the IBM alignment model 1 that uses vector representation of words, and ii)examining the use of similar source words to overcome the problem of rare source words and improving the alignments. We apply our method to English-French corpora and run the experiments with different sizes of sentence pairs. Our results show competitive performance against the baseline and in some cases improve the results up to 6.9{\%} in terms of precision.",
    bibtex_show={true},
}

@inproceedings{dadashkarimi-etal-2016-learning,
    abbr={Coling},
    title = "Learning to Weight Translations using Ordinal Linear Regression and Query-generated Training Data for Ad-hoc Retrieval with Long Queries",
    author = "Dadashkarimi, Javid  and
      Jalili Sabet, Masoud  and
      Shakery, Azadeh",
    booktitle = "Coling",
    year = "2016",
    address = "Osaka, Japan",
    publisher = "The COLING 2016 Organizing Committee",
    url = "https://aclanthology.org/C16-1162",
    pdf = "https://aclanthology.org/C16-1162.pdf",
    bib = "https://aclanthology.org/C16-1162.bib",
    pages = "1725--1733",
    abstract = "Ordinal regression which is known with learning to rank has long been used in information retrieval (IR). Learning to rank algorithms, have been tailored in document ranking, information filtering, and building large aligned corpora successfully. In this paper, we propose to use this algorithm for query modeling in cross-language environments. To this end, first we build a query-generated training data using pseudo-relevant documents to the query and all translation candidates. The pseudo-relevant documents are obtained by top-ranked documents in response to a translation of the original query. The class of each candidate in the training data is determined based on presence/absence of the candidate in the pseudo-relevant documents. We learn an ordinal regression model to score the candidates based on their relevance to the context of the query, and after that, we construct a query-dependent translation model using a softmax function. Finally, we re-weight the query based on the obtained model. Experimental results on French, German, Spanish, and Italian CLEF collections demonstrate that the proposed method achieves better results compared to state-of-the-art cross-language information retrieval methods, particularly in long queries with large training data.",
    bibtex_show={true},
}

